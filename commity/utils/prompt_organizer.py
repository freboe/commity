import re
from typing import Final

from commity.utils.token_counter import count_tokens

# Constants
MAX_DIFF_LENGTH: Final[int] = 15000
MAX_FILES_IN_SUMMARY: Final[int] = 30
MAX_COMPRESSED_LINES: Final[int] = 1000


def check_diff_length(diff_text, threshold=MAX_DIFF_LENGTH):
    if len(diff_text) > threshold:
        return (
            True,
            f"âš ï¸ Diff too long ({len(diff_text)} characters), it is recommended to submit in batches or simplify changesã€‚",
        )
    return False, ""


def generate_prompt_summary(diff_text):
    # æå–æ–‡ä»¶åå’Œä¿®æ”¹è¡Œæ•°ï¼ˆç¤ºä¾‹ç”¨ git diff ç»“æ„ï¼‰
    files = re.findall(r"diff --git a/(.+?) ", diff_text)
    summary = [f"- Change Fileï¼š{file}" for file in files[:MAX_FILES_IN_SUMMARY]]  # é™åˆ¶å‰Né¡¹
    return "ğŸ“ Change Summaryï¼š\n" + "\n".join(summary)


def compress_diff_to_bullets(diff_text, max_lines=MAX_COMPRESSED_LINES):
    lines = diff_text.splitlines()
    compressed = []

    for line in lines:
        if line.startswith("+") and not line.startswith("+++"):
            compressed.append(f"- Addï¼š{line[1:].strip()}")
        elif line.startswith("-") and not line.startswith("---"):
            compressed.append(f"- Deleteï¼š{line[1:].strip()}")

        if len(compressed) >= max_lines:
            # compressed.append("...å†…å®¹å·²æˆªæ–­")
            compressed.append("...<truncated>")
            break

    return "\n".join(compressed)


def _get_chars_per_token_ratio(text: str, provider: str) -> float:
    """æ ¹æ® provider å’Œæ–‡æœ¬å†…å®¹ä¼°ç®—å­—ç¬¦/token æ¯”ç‡ã€‚

    Args:
    ----
        text: è¦åˆ†æçš„æ–‡æœ¬
        provider: LLM provider

    Returns:
    -------
        å­—ç¬¦/token çš„ä¼°ç®—æ¯”ç‡

    """
    # æ£€æµ‹ CJK å­—ç¬¦å æ¯”
    cjk_count = sum(1 for char in text if ord(char) >= 0x4E00 and ord(char) <= 0x9FFF)
    cjk_ratio = cjk_count / len(text) if len(text) > 0 else 0

    # æ ¹æ® provider å’Œæ–‡æœ¬ç‰¹å¾è¿”å›ä¸åŒçš„æ¯”ç‡
    if provider == "gemini":
        if cjk_ratio > 0.3:
            return 2.0  # ä¸­æ–‡ä¸ºä¸»ï¼šçº¦ 2 å­—ç¬¦/token
        return 3.5  # è‹±æ–‡/ä»£ç ï¼šçº¦ 3.5 å­—ç¬¦/token

    if provider in ("openai", "openrouter"):
        if cjk_ratio > 0.3:
            return 2.5  # OpenAI å¯¹ä¸­æ–‡çš„ token åŒ–è¾ƒç²—
        return 4.0  # è‹±æ–‡æ ‡å‡†ï¼š4 å­—ç¬¦/token

    # Ollama å’Œå…¶ä»– provider ä½¿ç”¨ä¿å®ˆä¼°ç®—
    return 3.5


def summary_and_tokens_checker(
    diff_text: str, max_output_tokens: int, model_name: str, provider: str = "openai"
) -> str:
    """æ·»åŠ æ€»ç»“å’Œå‹ç¼©ç‰ˆæœ¬çš„diffï¼Œæ„å»ºæœ‰æ•ˆé•¿åº¦çš„tokensçš„æç¤ºè¯è¯­ï¼Œé¿å…è¿‡é•¿å¯¼è‡´æ¨¡å‹ç”Ÿæˆå¤±è´¥

    é‡‡ç”¨ä¸‰çº§å‹ç¼©ç­–ç•¥ï¼š
    1. æ£€æŸ¥åŸå§‹ diff æ˜¯å¦åœ¨é™åˆ¶å†…
    2. å‹ç¼©ä¸º bullet points æ ¼å¼
    3. å¼ºåˆ¶å­—ç¬¦æˆªæ–­ï¼ˆä¿ç•™å…³é”®ä¿¡æ¯ï¼‰

    Args:
    ----
        diff_text: Git diff text to check
        max_output_tokens: Maximum tokens allowed
        model_name: Model name for token counting
        provider: LLM provider (openai, gemini, ollama, openrouter)

    Returns:
    -------
        Original or compressed diff text that fits within token limit

    """
    # ç¬¬ä¸€çº§ï¼šæ£€æŸ¥åŸå§‹ diff
    token_count = count_tokens(diff_text, model_name, provider)
    if token_count <= max_output_tokens:
        return diff_text

    # ç¬¬äºŒçº§ï¼šå‹ç¼©ä¸º bullet points
    _, warning_msg = check_diff_length(diff_text)
    prompt_summary = generate_prompt_summary(diff_text)
    compressed_diff = compress_diff_to_bullets(diff_text)

    compressed_prompt = f"{warning_msg}\n{prompt_summary}\n\nğŸ” Change details (compressed version)ï¼š\n{compressed_diff}"

    # æ£€æŸ¥å‹ç¼©åçš„ token æ•°ï¼ˆç¼“å­˜ç»“æœé¿å…é‡å¤è®¡ç®—ï¼‰
    compressed_token_count = count_tokens(compressed_prompt, model_name, provider)
    if compressed_token_count <= max_output_tokens:
        return compressed_prompt

    # ç¬¬ä¸‰çº§ï¼šå¼ºåˆ¶æˆªæ–­
    excess_tokens = compressed_token_count - max_output_tokens

    # æ ¹æ® provider åŠ¨æ€è°ƒæ•´å­—ç¬¦/token æ¯”ç‡
    chars_per_token = _get_chars_per_token_ratio(compressed_prompt, provider)
    chars_to_remove = int(excess_tokens * chars_per_token)

    if len(compressed_prompt) > chars_to_remove + 100:  # ä¿ç•™è‡³å°‘ 100 å­—ç¬¦
        # ä¿ç•™å‰ 70% å’Œå 10%ï¼Œåˆ é™¤ä¸­é—´éƒ¨åˆ†ï¼ˆä¿ç•™å…³é”®ä¸Šä¸‹æ–‡ï¼‰
        keep_start = int((len(compressed_prompt) - chars_to_remove) * 0.7)
        keep_end = int((len(compressed_prompt) - chars_to_remove) * 0.1)
        truncated_prompt = (
            compressed_prompt[:keep_start]
            + f"\n\n...<truncated {chars_to_remove} chars>...\n\n"
            + compressed_prompt[-keep_end:]
        )
        return truncated_prompt

    # å…œåº•ï¼šå¦‚æœå‹ç¼©åè¿˜æ˜¯å¤ªé•¿ï¼Œè¿”å›å‹ç¼©ç‰ˆæœ¬è®©æ¨¡å‹å°è¯•å¤„ç†
    return compressed_prompt
